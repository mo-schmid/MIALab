Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{InstituteofElectricalandElectronicsEngineers.DelhiSection,
abstract = {" ... Proceedings of the 13th INDIACom; 2019 06th International Conference on "Computing for Sustainable Global Development"--PDF preface. "IEEE Part Number:CFP1983W-ART."},
author = {{Institute of Electrical and Electronics Engineers. Delhi Section} and {Bharati Vidyapeeth University (Pune}, India) and {INDIAcom (Conference) (13th : 2019 : New Delhi}, India)},
file = {::},
isbn = {9789380544342},
title = {{Proceedings of the 2019 6th International Conference on Computing for Sustainable Global Development (INDIACom) : 13 - 15 March 2019, Bharati Vidyapeeth, New Delhi.}}
}
@article{Chen2016,
abstract = {In this work we address the task of semantic image segmentation with Deep Learning and make three main contributions that are experimentally shown to have substantial practical merit. First, we highlight convolution with upsampled filters, or 'atrous convolution', as a powerful tool in dense prediction tasks. Atrous convolution allows us to explicitly control the resolution at which feature responses are computed within Deep Convolutional Neural Networks. It also allows us to effectively enlarge the field of view of filters to incorporate larger context without increasing the number of parameters or the amount of computation. Second, we propose atrous spatial pyramid pooling (ASPP) to robustly segment objects at multiple scales. ASPP probes an incoming convolutional feature layer with filters at multiple sampling rates and effective fields-of-views, thus capturing objects as well as image context at multiple scales. Third, we improve the localization of object boundaries by combining methods from DCNNs and probabilistic graphical models. The commonly deployed combination of max-pooling and downsampling in DCNNs achieves invariance but has a toll on localization accuracy. We overcome this by combining the responses at the final DCNN layer with a fully connected Conditional Random Field (CRF), which is shown both qualitatively and quantitatively to improve localization performance. Our proposed "DeepLab" system sets the new state-of-art at the PASCAL VOC-2012 semantic image segmentation task, reaching 79.7{\%} mIOU in the test set, and advances the results on three other datasets: PASCAL-Context, PASCAL-Person-Part, and Cityscapes. All of our code is made publicly available online.},
archivePrefix = {arXiv},
arxivId = {1606.00915},
author = {Chen, Liang-Chieh and Papandreou, George and Kokkinos, Iasonas and Murphy, Kevin and Yuille, Alan L.},
eprint = {1606.00915},
file = {::},
month = {jun},
title = {{DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs}},
url = {http://arxiv.org/abs/1606.00915},
year = {2016}
}
@article{Kamnitsas2017,
abstract = {We propose a dual pathway, 11-layers deep, three-dimensional Convolutional Neural Network for the challenging task of brain lesion segmentation. The devised architecture is the result of an in-depth analysis of the limitations of current networks proposed for similar applications. To overcome the computational burden of processing 3D medical scans, we have devised an efficient and effective dense training scheme which joins the processing of adjacent image patches into one pass through the network while automatically adapting to the inherent class imbalance present in the data. Further, we analyze the development of deeper, thus more discriminative 3D CNNs. In order to incorporate both local and larger contextual information, we employ a dual pathway architecture that processes the input images at multiple scales simultaneously. For post-processing of the network's soft segmentation, we use a 3D fully connected Conditional Random Field which effectively removes false positives. Our pipeline is extensively evaluated on three challenging tasks of lesion segmentation in multi-channel MRI patient data with traumatic brain injuries, brain tumours, and ischemic stroke. We improve on the state-of-the-art for all three applications, with top ranking performance on the public benchmarks BRATS 2015 and ISLES 2015. Our method is computationally efficient, which allows its adoption in a variety of research and clinical settings. The source code of our implementation is made publicly available.},
archivePrefix = {arXiv},
arxivId = {1603.05959},
author = {Kamnitsas, Konstantinos and Ledig, Christian and Newcombe, Virginia F.J. and Simpson, Joanna P. and Kane, Andrew D. and Menon, David K. and Rueckert, Daniel and Glocker, Ben},
doi = {10.1016/j.media.2016.10.004},
eprint = {1603.05959},
file = {:Users/roberto/Desktop/HS20/03-MIA{\_}Lab/04-Project/Recources/CRF{\_}brain{\_}lesion.pdf:pdf},
issn = {13618423},
journal = {Medical Image Analysis},
keywords = {3D convolutional neural network,Brain lesions,Deep learning,Fully connected CRF,Segmentation},
month = {feb},
pages = {61--78},
pmid = {27865153},
publisher = {Elsevier B.V.},
title = {{Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation}},
volume = {36},
year = {2017}
}
@article{Liu2018,
abstract = {Efficient and accurate semantic segmentation is the key technique for automatic remote sensing image analysis. While there have been many segmentation methods based on traditional hand-craft feature extractors, it is still challenging to process high-resolution and large-scale remote sensing images. In this work, a novel patch-wise semantic segmentation method with a new training strategy based on fully convolutional networks is presented to segment common land resources. First, to handle the high-resolution image, the images are split as local patches and then a patch-wise network is built. Second, training data is preprocessed in several ways to meet the specific characteristics of remote sensing images, i.e., color imbalance, object rotation variations and lens distortion. Third, a multi-scale training strategy is developed to solve the severe scale variation problem. In addition, the impact of conditional random field (CRF) is studied to improve the precision. The proposed method was evaluated on a dataset collected from a capital city in West China with the Gaofen-2 satellite. The dataset contains ten common land resources (Grassland, Road, etc.). The experimental results show that the proposed algorithm achieves 54.96{\%} in terms of mean intersection over union (MIoU) and outperforms other state-of-the-art methods in remote sensing image segmentation.},
author = {Liu, Yan and Ren, Qirui and Geng, Jiahui and Ding, Meng and Li, Jiangyun},
doi = {10.3390/s18103232},
file = {::},
issn = {14248220},
journal = {Sensors (Switzerland)},
keywords = {Fully convolutional network,Image segmentation,Multi-scale,Patch-wise,Remote sensing},
month = {oct},
number = {10},
pmid = {30257526},
publisher = {MDPI AG},
title = {{Efficient patch-wise semantic segmentation for large-scale remote sensing images}},
volume = {18},
year = {2018}
}
@article{Krahenbuhl2012,
abstract = {Most state-of-the-art techniques for multi-class image segmentation and labeling use conditional random fields defined over pixels or image regions. While region-level models often feature dense pairwise connectivity, pixel-level models are considerably larger and have only permitted sparse graph structures. In this paper, we consider fully connected CRF models defined on the complete set of pixels in an image. The resulting graphs have billions of edges, making traditional inference algorithms impractical. Our main contribution is a highly efficient approximate inference algorithm for fully connected CRF models in which the pairwise edge potentials are defined by a linear combination of Gaussian kernels. Our experiments demonstrate that dense connectivity at the pixel level substantially improves segmentation and labeling accuracy.},
archivePrefix = {arXiv},
arxivId = {1210.5644},
author = {Kr{\"{a}}henb{\"{u}}hl, Philipp and Koltun, Vladlen},
eprint = {1210.5644},
file = {::},
month = {oct},
title = {{Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials}},
url = {http://arxiv.org/abs/1210.5644},
year = {2012}
}
@article{Pereira2016,
abstract = {Background The segmentation of brain tissue into cerebrospinal fluid, gray matter, and white matter in magnetic resonance imaging scans is an important procedure to extract regions of interest for quantitative analysis and disease assessment. Manual segmentation requires skilled experts, being a laborious and time-consuming task; therefore, reliable and robust automatic segmentation methods are necessary. New method We propose a segmentation framework based on a Conditional Random Field for brain tissue segmentation, with a Random Forest encoding the likelihood function. The features include intensities, gradients, probability maps, and locations. Additionally, skull stripping is critical for achieving an accurate segmentation; thus, after extracting the brain we propose to refine its boundary during segmentation. Results The proposed framework was evaluated on the MR Brain Image Segmentation Challenge and the Internet Brain Segmentation Repository databases. The segmentations of brain tissues obtained with the proposed algorithm were competitive both in normal and diseased subjects. The skull stripping refinement significantly improved the results, when comparing against no refinement. Comparison with existing methods In the MR Brain Image Segmentation Challenge database, the results were competitive when comparing with top methods. In the Internet Brain Segmentation Repository database, the proposed approach outperformed other well-established algorithms. Conclusions The combination of a Random Forest and Conditional Random Field for brain tissue segmentation performed well for normal and diseased subjects. Additionally, refinement of the skull stripping at segmentation time is feasible in learning-based methods and significantly improves the segmentation of cerebrospinal fluid and intracranial volume.},
author = {Pereira, S{\'{e}}rgio and Pinto, Adriano and Oliveira, Jorge and Mendrik, Adri{\"{e}}nne M. and Correia, Jos{\'{e}} H. and Silva, Carlos A.},
doi = {10.1016/j.jneumeth.2016.06.017},
file = {::},
issn = {1872678X},
journal = {Journal of Neuroscience Methods},
keywords = {Brain segmentation,Conditional Random Field,Magnetic resonance imaging,Random Forest},
month = {sep},
pages = {111--123},
pmid = {27329005},
publisher = {Elsevier B.V.},
title = {{Automatic brain tissue segmentation in MR images using Random Forests and Conditional Random Fields}},
volume = {270},
year = {2016}
}
